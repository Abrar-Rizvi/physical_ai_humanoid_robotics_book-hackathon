# Data Model: RAG Embeddings Pipeline

**Feature**: 006-rag-embeddings-pipeline
**Branch**: `006-rag-embeddings-pipeline`
**Date**: 2025-12-12

## Overview

This document defines the data structures and relationships for the RAG embeddings pipeline, which extracts content from Docusaurus book pages, generates embeddings, and stores them in Qdrant vector database.

## Entity Relationship Diagram

```
┌─────────────────────┐
│  Content Document   │
│  (Scraped Page)     │
└──────────┬──────────┘
           │
           │ 1:N (chunked into)
           │
           ▼
┌─────────────────────┐
│   Text Segment      │
│   (Chunk)           │
└──────────┬──────────┘
           │
           │ 1:1 (generates)
           │
           ▼
┌─────────────────────┐      ┌─────────────────────┐
│  Vector Embedding   │◄─────│ Embedding Metadata  │
│  (Cohere)           │ 1:1  │ (Qdrant Payload)    │
└──────────┬──────────┘      └─────────────────────┘
           │
           │ N:1 (belongs to)
           │
           ▼
┌─────────────────────┐
│   Processing Job    │
│   (Pipeline Run)    │
└─────────────────────┘
```

## Core Entities

### 1. Content Document

Represents a single Docusaurus book page scraped from a URL.

**Attributes**:

| Field | Type | Required | Description | Validation Rules |
|-------|------|----------|-------------|------------------|
| `source_url` | `str` | Yes | Original page URL | Must be valid HTTP/HTTPS URL |
| `page_title` | `str` | Yes | Page title from `<h1>` or `<title>` | Max 500 characters |
| `content_html` | `str` | No | Raw HTML content | Stored for debugging only |
| `content_text` | `str` | Yes | Extracted plain text | Min 50 characters |
| `extraction_timestamp` | `datetime` (ISO 8601) | Yes | When content was extracted | UTC timezone |
| `content_hash` | `str` (SHA-256) | Yes | Hash of content_text | For change detection (FR-014) |
| `word_count` | `int` | Yes | Number of words in content | Min 10 |
| `chapter` | `str` | No | Chapter/section from heading hierarchy | Extracted from HTML structure |
| `section` | `str` | No | Section title | Extracted from HTML structure |
| `has_code` | `bool` | Yes | Whether page contains code blocks | Default: False |
| `has_images` | `bool` | Yes | Whether page contains images | Default: False |

**Lifecycle**:
1. Created during URL scraping phase
2. Persisted temporarily during processing
3. Archived or discarded after successful chunking

**Example**:
```python
{
    "source_url": "https://book.example.com/chapter3/vector-databases",
    "page_title": "Chapter 3: Vector Databases",
    "content_text": "Vector databases are specialized systems...",
    "extraction_timestamp": "2025-12-12T10:30:00Z",
    "content_hash": "sha256:abc123def456...",
    "word_count": 1247,
    "chapter": "3",
    "section": "Introduction to Qdrant",
    "has_code": True,
    "has_images": False
}
```

---

### 2. Text Segment (Chunk)

A chunked portion of a Content Document, suitable for embedding generation.

**Attributes**:

| Field | Type | Required | Description | Validation Rules |
|-------|------|----------|-------------|------------------|
| `segment_id` | `UUID` | Yes | Unique identifier | Auto-generated UUID v4 |
| `parent_document_url` | `str` | Yes | Reference to source document | FK to Content Document |
| `segment_text` | `str` | Yes | Chunked text content | 100-500 tokens (per spec SC-007) |
| `token_count` | `int` | Yes | Actual token count | Min 100, Max 512 |
| `character_count` | `int` | Yes | Character count | Informational |
| `chunk_index` | `int` | Yes | Position within parent document | 0-indexed, sequential |
| `total_chunks` | `int` | Yes | Total chunks in parent document | For progress tracking |
| `overlap_with_previous` | `int` | Yes | Token overlap with previous chunk | 0-100 tokens |
| `overlap_with_next` | `int` | Yes | Token overlap with next chunk | 0-100 tokens |
| `heading_hierarchy` | `List[str]` | No | Chapter/section path | E.g., ["Ch3", "Sec 3.2", "Subsec 3.2.1"] |
| `contains_code` | `bool` | Yes | Whether chunk contains code | Default: False |

**Validation Rules**:
- `token_count` must be within 100-500 range (per spec SC-007)
- `chunk_index` must be unique within parent document
- `segment_text` must not be empty

**Example**:
```python
{
    "segment_id": "550e8400-e29b-41d4-a716-446655440000",
    "parent_document_url": "https://book.example.com/chapter3",
    "segment_text": "Qdrant is a vector database that supports...",
    "token_count": 387,
    "character_count": 1542,
    "chunk_index": 2,
    "total_chunks": 15,
    "overlap_with_previous": 50,
    "overlap_with_next": 50,
    "heading_hierarchy": ["Chapter 3", "Section 3.2", "Qdrant Setup"],
    "contains_code": True
}
```

---

### 3. Vector Embedding

The numerical representation of a Text Segment generated by Cohere.

**Attributes**:

| Field | Type | Required | Description | Validation Rules |
|-------|------|----------|-------------|------------------|
| `embedding_id` | `UUID` | Yes | Unique identifier | Same as segment_id |
| `vector` | `List[float]` | Yes | 1024-dimensional embedding | Length must be exactly 1024 |
| `model` | `str` | Yes | Cohere model used | Must be "embed-english-v3.0" |
| `input_type` | `str` | Yes | Embedding type | Must be "search_document" |
| `generation_timestamp` | `datetime` (ISO 8601) | Yes | When embedding was generated | UTC timezone |
| `generation_latency_ms` | `int` | No | API latency in milliseconds | For monitoring |
| `batch_id` | `UUID` | No | Batch processing ID | Groups embeddings from same API call |

**Validation Rules**:
- `vector` length must be exactly 1024 (per research: Cohere embed-english-v3.0)
- `model` must match configured model in environment
- `vector` values must be floats (normalized by Cohere)

**Storage**:
- Stored in Qdrant vector database
- Not persisted in application database (too large)

**Example**:
```python
{
    "embedding_id": "550e8400-e29b-41d4-a716-446655440000",
    "vector": [0.123, -0.456, 0.789, ..., 0.321],  # 1024 floats
    "model": "embed-english-v3.0",
    "input_type": "search_document",
    "generation_timestamp": "2025-12-12T10:30:15Z",
    "generation_latency_ms": 234,
    "batch_id": "660e8400-e29b-41d4-a716-446655440001"
}
```

---

### 4. Embedding Metadata (Qdrant Payload)

Associated information for each embedding, stored in Qdrant payload.

**Attributes**:

| Field | Type | Required | Description | Validation Rules |
|-------|------|----------|-------------|------------------|
| `text` | `str` | Yes | Original segment text | Same as segment_text |
| `source_url` | `str` | Yes | Page URL | Must be valid URL |
| `page_title` | `str` | Yes | Page title | Max 500 characters |
| `chapter` | `str` | No | Chapter identifier | From heading hierarchy |
| `section` | `str` | No | Section title | From heading hierarchy |
| `subsection` | `str` | No | Subsection title | From heading hierarchy |
| `chunk_index` | `int` | Yes | Position in document | 0-indexed |
| `total_chunks` | `int` | Yes | Total chunks in document | For context |
| `token_count` | `int` | Yes | Tokens in chunk | 100-500 |
| `extraction_timestamp` | `str` (ISO 8601) | Yes | When content was extracted | UTC |
| `content_hash` | `str` (SHA-256) | Yes | Hash of parent document | For change detection |
| `has_code` | `bool` | Yes | Contains code blocks | Default: False |
| `embedding_model` | `str` | Yes | Cohere model version | "embed-english-v3.0" |

**Validation Rules** (per spec FR-006):
- All required fields must be present
- `source_url`, `page_title`, and `extraction_timestamp` are mandatory
- Metadata size should be <1KB to optimize Qdrant storage

**Qdrant Storage Structure**:
```python
{
    "id": "550e8400-e29b-41d4-a716-446655440000",  # UUID string
    "vector": [0.123, -0.456, ...],  # 1024 floats
    "payload": {
        "text": "Qdrant is a vector database...",
        "source_url": "https://book.example.com/chapter3",
        "page_title": "Chapter 3: Vector Databases",
        "chapter": "3",
        "section": "3.2 Qdrant Setup",
        "subsection": "3.2.1 Installation",
        "chunk_index": 2,
        "total_chunks": 15,
        "token_count": 387,
        "extraction_timestamp": "2025-12-12T10:30:00Z",
        "content_hash": "sha256:abc123...",
        "has_code": True,
        "embedding_model": "embed-english-v3.0"
    }
}
```

---

### 5. Processing Job

Represents a single pipeline execution (full run from URL list to Qdrant storage).

**Attributes**:

| Field | Type | Required | Description | Validation Rules |
|-------|------|----------|-------------|------------------|
| `job_id` | `UUID` | Yes | Unique job identifier | Auto-generated |
| `start_time` | `datetime` (ISO 8601) | Yes | Job start timestamp | UTC |
| `end_time` | `datetime` (ISO 8601) | No | Job completion timestamp | UTC |
| `status` | `enum` | Yes | Current job status | One of: running, completed, failed, partial |
| `urls_requested` | `List[str]` | Yes | Input URL list | Min 1 URL |
| `urls_processed` | `int` | Yes | Successfully processed URLs | Default: 0 |
| `urls_failed` | `int` | Yes | Failed URLs | Default: 0 |
| `documents_extracted` | `int` | Yes | Documents scraped | Default: 0 |
| `chunks_generated` | `int` | Yes | Total chunks created | Default: 0 |
| `embeddings_generated` | `int` | Yes | Embeddings created | Default: 0 |
| `embeddings_stored` | `int` | Yes | Embeddings in Qdrant | Default: 0 |
| `error_log` | `List[Dict]` | No | Errors encountered | List of {url, error, timestamp} |
| `processing_time_seconds` | `float` | No | Total execution time | Calculated: end_time - start_time |
| `average_tokens_per_chunk` | `float` | No | Avg chunk size | For quality monitoring |

**Status Enum**:
- `running`: Job in progress
- `completed`: All URLs processed successfully
- `failed`: Job failed with critical error
- `partial`: Some URLs succeeded, some failed

**Validation Rules** (per spec SC-006):
- `processing_time_seconds` should be <600s (10 minutes) for 50-page book
- Success rate: `urls_processed / len(urls_requested)` should be ≥0.95 (per spec SC-001)

**Example**:
```python
{
    "job_id": "770e8400-e29b-41d4-a716-446655440002",
    "start_time": "2025-12-12T10:00:00Z",
    "end_time": "2025-12-12T10:08:34Z",
    "status": "completed",
    "urls_requested": [
        "https://book.example.com/chapter1",
        "https://book.example.com/chapter2",
        "https://book.example.com/chapter3"
    ],
    "urls_processed": 3,
    "urls_failed": 0,
    "documents_extracted": 3,
    "chunks_generated": 45,
    "embeddings_generated": 45,
    "embeddings_stored": 45,
    "error_log": [],
    "processing_time_seconds": 514.2,
    "average_tokens_per_chunk": 387.3
}
```

---

## Data Flows

### 1. Extraction Flow

```
URL List
  │
  ├─> Fetch HTML (requests)
  │
  ├─> Parse HTML (BeautifulSoup)
  │
  ├─> Extract Text (remove nav/footer)
  │
  └─> Content Document
```

### 2. Chunking Flow

```
Content Document
  │
  ├─> Tokenize (tiktoken)
  │
  ├─> Split (LangChain RecursiveCharacterTextSplitter)
  │     - Target: 400 tokens
  │     - Overlap: 50 tokens
  │     - Semantic boundaries
  │
  └─> Text Segments (List)
```

### 3. Embedding Flow

```
Text Segments
  │
  ├─> Batch (96 segments per request)
  │
  ├─> Generate Embeddings (Cohere API)
  │     - Model: embed-english-v3.0
  │     - Input type: search_document
  │     - Dimension: 1024
  │
  └─> Vector Embeddings (List)
```

### 4. Storage Flow

```
Vector Embeddings + Metadata
  │
  ├─> Create Qdrant Points
  │     - ID: segment_id
  │     - Vector: embedding
  │     - Payload: metadata
  │
  ├─> Upsert to Qdrant
  │     - Collection: book_embeddings
  │     - Distance: Cosine
  │
  └─> Stored in Qdrant
```

---

## Validation Rules Summary

Based on spec requirements:

1. **Content Extraction** (FR-001, SC-001):
   - Must extract text from ≥95% of URLs
   - Minimum 50 characters per document

2. **Text Chunking** (SC-007):
   - 95% of chunks between 100-500 tokens
   - 0% exceed 512 tokens (Cohere limit)

3. **Embedding Storage** (FR-005, SC-002):
   - 100% metadata accuracy (source URL, title match)
   - All embeddings have complete payload

4. **Retrieval Quality** (SC-003):
   - Similarity scores ≥0.7 for known-good queries
   - Metadata enables filtering and context reconstruction

5. **Performance** (SC-004):
   - Process 50-page book in <10 minutes
   - Support ≥10 concurrent URLs

---

## Storage Estimates

### Per 50-Page Book:

| Component | Count | Size | Total |
|-----------|-------|------|-------|
| Documents | 50 | ~2 KB | ~100 KB |
| Chunks | 500 | ~500 bytes | ~250 KB |
| Embeddings | 500 | 1024 floats × 4 bytes | ~2 MB |
| Metadata | 500 | ~1 KB | ~500 KB |
| **Total** | - | - | **~2.85 MB** |

### Qdrant Storage (per collection):

- Vector dimension: 1024 (float32)
- Per vector: 4 KB (1024 × 4 bytes)
- Per payload: ~1 KB (metadata JSON)
- **Total per embedding: ~5 KB**
- **500 embeddings: ~2.5 MB**

---

## Change Detection Strategy

Per spec FR-014 (maintain processing state for resume):

1. **Content Hash**:
   - SHA-256 of `content_text`
   - Stored in Qdrant metadata
   - Used for change detection on re-runs

2. **Update Logic**:
   ```python
   if existing_hash != new_hash:
       # Content changed - re-process
       delete_old_embeddings(url)
       generate_new_embeddings(url)
   else:
       # No change - skip
       skip_url(url)
   ```

3. **Incremental Updates**:
   - Query Qdrant for existing `source_url`
   - Compare `content_hash`
   - Only re-embed changed pages

---

## Error Handling

### Error Types in Processing Job:

```python
error_log_entry = {
    "url": "https://book.example.com/page",
    "stage": "extraction",  # extraction, chunking, embedding, storage
    "error_type": "HTTPError",  # HTTPError, ParseError, APIError, StorageError
    "error_message": "404 Not Found",
    "timestamp": "2025-12-12T10:05:23Z",
    "retry_count": 3,
    "resolution": "skipped"  # skipped, retried, manual_intervention
}
```

---

## Next Steps

This data model will be implemented in `backend/main.py` using:
- Python dataclasses or Pydantic models
- Type hints for validation
- JSON serialization for logging and debugging
- Qdrant Python client for vector storage

See `quickstart.md` for implementation examples.
